import re
import unicodedata
from typing import List, Dict, Tuple, Optional
import logging
import numpy as np

logger = logging.getLogger("speech_analyzer")


def number_to_words(num_str: str) -> str:
    """Convert a number string to its spoken form."""
    try:
        num = int(num_str)
        # Handle common numbers that appear in speech
        ones = ["", "one", "two", "three", "four", "five", "six", "seven", "eight", "nine"]
        teens = ["ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", "seventeen", "eighteen", "nineteen"]
        tens = ["", "", "twenty", "thirty", "forty", "fifty", "sixty", "seventy", "eighty", "ninety"]
        
        if num == 0:
            return "zero"
        elif 1 <= num <= 9:
            return ones[num]
        elif 10 <= num <= 19:
            return teens[num - 10]
        elif 20 <= num <= 99:
            if num % 10 == 0:
                return tens[num // 10]
            else:
                return tens[num // 10] + " " + ones[num % 10]
        elif 100 <= num <= 999:
            if num % 100 == 0:
                return ones[num // 100] + " hundred"
            else:
                return ones[num // 100] + " hundred " + number_to_words(str(num % 100))
        elif 1000 <= num <= 999999:
            if num % 1000 == 0:
                return number_to_words(str(num // 1000)) + " thousand"
            else:
                return number_to_words(str(num // 1000)) + " thousand " + number_to_words(str(num % 1000))
        else:
            # For very large numbers, just return the original
            return num_str
    except ValueError:
        # If it's not a valid integer, return as-is
        return num_str


def normalize_text_for_phonemization(text: str) -> str:
    """Normalize text by converting numbers to their spoken form."""
    
    def replace_ordinal(match):
        """Convert ordinal numbers to words."""
        num = match.group(1)
        suffix = match.group(2).lower()
        
        # Convert base number to words
        base_words = number_to_words(num)
        
        # Handle ordinal endings
        if base_words.endswith('one'):
            return base_words[:-3] + 'first'
        elif base_words.endswith('two'):
            return base_words[:-3] + 'second'
        elif base_words.endswith('three'):
            return base_words[:-5] + 'third'
        elif base_words.endswith('five'):
            return base_words[:-4] + 'fifth'
        elif base_words.endswith('eight'):
            return base_words[:-5] + 'eighth'
        elif base_words.endswith('nine'):
            return base_words[:-4] + 'ninth'
        elif base_words.endswith('twelve'):
            return base_words[:-6] + 'twelfth'
        elif base_words.endswith('twenty'):
            return base_words[:-6] + 'twentieth'
        elif base_words.endswith('thirty'):
            return base_words[:-6] + 'thirtieth'
        elif base_words.endswith('forty'):
            return base_words[:-5] + 'fortieth'
        elif base_words.endswith('fifty'):
            return base_words[:-5] + 'fiftieth'
        elif base_words.endswith('sixty'):
            return base_words[:-5] + 'sixtieth'
        elif base_words.endswith('seventy'):
            return base_words[:-7] + 'seventieth'
        elif base_words.endswith('eighty'):
            return base_words[:-6] + 'eightieth'
        elif base_words.endswith('ninety'):
            return base_words[:-6] + 'ninetieth'
        else:
            # Default: add 'th' to the end
            return base_words + 'th'
    
    def replace_number(match):
        return number_to_words(match.group())
    
    # First replace ordinal numbers (1st, 2nd, 3rd, 4th, etc.)
    normalized = re.sub(r'\b(\d+)(st|nd|rd|th)\b', replace_ordinal, text, flags=re.IGNORECASE)
    
    # Then replace standalone numbers with their word forms
    normalized = re.sub(r'\b\d+\b', replace_number, normalized)
    
    return normalized


def tokenize_words(text: str) -> List[str]:
    # Updated to handle alphanumeric tokens (numbers + letters) like "17th", "1st", "2nd", etc.
    return [w for w in re.findall(r"[A-Za-z0-9]+'?[A-Za-z0-9]*|[A-Za-z0-9]+", text or "")] 


def split_diphthongs(seq: List[str]) -> List[str]:
    out: List[str] = []
    for p in seq:
        if p == "e…™":
            out += ["e", "…™"]
        elif p == "o ä":
            out += ["o", " ä"]
        elif p == "a…™":
            out += ["a", "…™"]
        elif p == "a ä":
            out += ["a", " ä"]
        elif p == "…î…™":
            out += ["…î", "…™"]
        elif p == "…™…ô":
            out += ["…™", "…ô"]
        elif p == " ä…ô":
            out += [" ä", "…ô"]
        else:
            out.append(p)
    return out


def normalize_ipa(seq: List[str]) -> List[str]:
    out: List[str] = []
    for p in split_diphthongs(seq):
        nf = unicodedata.normalize("NFD", p)
        base = "".join(ch for ch in nf if not unicodedata.combining(ch) and ch not in {"Àê", "Àë"})
        base = (base
            .replace("t…ï", "t É").replace("t…ï ∞", "t É").replace("t Ç", "t É")
            .replace("d ë", "d í")
            .replace("…ï", " É").replace(" Ç", " É").replace(" ê", " í")
            .replace("…π", "r").replace("…æ", "r")
            .replace("x", "h").replace("y", "j")
            .replace("…¥", "n").replace("…´", "l")
            .replace("…í", "…ë").replace("…§", " å")
        )
        if base:
            out.append(base)
    return out


def normalize_ipa_preserve_diphthongs(seq: List[str]) -> List[str]:
    """Normalize IPA but preserve diphthongs (for Allosaurus which we already fixed)."""
    out: List[str] = []
    for p in seq:  # Skip split_diphthongs() to preserve our reconstructed diphthongs
        nf = unicodedata.normalize("NFD", p)
        base = "".join(ch for ch in nf if not unicodedata.combining(ch) and ch not in {"Àê", "Àë"})
        base = (base
            .replace("t…ï", "t É").replace("t…ï ∞", "t É").replace("t Ç", "t É")
            .replace("d ë", "d í")
            .replace("…ï", " É").replace(" Ç", " É").replace(" ê", " í")
            .replace("…π", "r").replace("…æ", "r")
            .replace("x", "h").replace("y", "j")
            .replace("…¥", "n").replace("…´", "l")
            .replace("…í", "…ë").replace("…§", " å")
        )
        if base:
            out.append(base)
    return out


# Lightweight English fallback phonemizer using g2p_en (ARPABET ‚Üí IPA)
_ARPABET_TO_IPA = {
    "AA": "…ë", "AE": "√¶", "AH": " å", "AO": "…î", "AW": "a ä", "AY": "a…™",
    "B": "b", "CH": "t É", "D": "d", "DH": "√∞", "EH": "…õ", "ER": "…ù",
    "EY": "e…™", "F": "f", "G": "…°", "HH": "h", "IH": "…™", "IY": "i",
    "JH": "d í", "K": "k", "L": "l", "M": "m", "N": "n", "NG": "≈ã",
    "OW": "o ä", "OY": "…î…™", "P": "p", "R": "r", "S": "s", "SH": " É",
    "T": "t", "TH": "Œ∏", "UH": " ä", "UW": "u", "V": "v", "W": "w",
    "Y": "j", "Z": "z", "ZH": " í",
}


def arpabet_tokens_to_ipa(tokens: List[str]) -> List[str]:
    out: List[str] = []
    for t in tokens:
        t = t.strip().upper()
        if not t:
            continue
        # remove stress digits from vowels
        if t[-1:].isdigit():
            t = t[:-1]
        if t in _ARPABET_TO_IPA:
            out.append(_ARPABET_TO_IPA[t])
    return out


_phonemize_cache: Dict[str, List[str]] = {}


def phonemize_words_en(text: str) -> List[List[str]]:
    # Normalize numbers to their spoken form before phonemization
    normalized_text = normalize_text_for_phonemization(text)
    logger.debug(f"Normalized text for phonemization: '{text}' -> '{normalized_text}'")
    
    words = tokenize_words(normalized_text)
    ipa_per_word: List[List[str]] = []
    # Try phonemizer/espeak first (if available)
    try:
        from phonemizer import phonemize
        from phonemizer.separator import Separator
        # Attempt to help locate espeak-ng on macOS Homebrew installs
        import os
        import glob
        if not os.environ.get("PHONEMIZER_ESPEAK_LIBRARY"):
            for p in (
                "/opt/homebrew/Cellar/espeak-ng/*/lib/libespeak-ng.1.dylib",
                "/opt/homebrew/lib/libespeak-ng.1.dylib",
                "/opt/homebrew/lib/libespeak-ng.dylib",
                "/usr/local/lib/libespeak-ng.dylib",
            ):
                matches = glob.glob(p)
                if matches:
                    os.environ["PHONEMIZER_ESPEAK_LIBRARY"] = matches[0]
                    logger.info(f"Found espeak-ng library at: {matches[0]}")
                    break
        # Batch phonemize as a list of words to preserve boundaries reliably
        ipa_list = phonemize(
            words,
            language="en-us",
            backend="espeak",
            strip=True,
            with_stress=False,
            separator=Separator(phone=" ", word="|"),
        )
        if isinstance(ipa_list, str):
            ipa_list = [ipa_list]
        # Ensure 1:1 with input words; if library returns fewer/more, fall back per word
        if len(ipa_list) != len(words):
            ipa_list = [
                phonemize(
                    w,
                    language="en-us",
                    backend="espeak",
                    strip=True,
                    with_stress=False,
                    separator=Separator(phone=" ", word="|"),
                )
                for w in words
            ]
        for seg in ipa_list:
            key = seg
            if key in _phonemize_cache:
                phones = _phonemize_cache[key]
            else:
                phones = [p for p in str(seg).strip().split() if p]
                _phonemize_cache[key] = phones
            ipa_per_word.append(phones)
        return ipa_per_word
    except Exception as exc:
        logger.warning("Phonemizer/espeak unavailable, falling back to g2p_en: %s", exc)
    # Fallback: g2p_en
    try:
        from g2p_en import G2p
        # Ensure required NLTK data exists (for POS tagger used by g2p_en)
        try:
            import nltk
            for pkg in ("averaged_perceptron_tagger_eng", "averaged_perceptron_tagger", "punkt"):
                try:
                    nltk.data.find(f"taggers/{pkg}") if "tagger" in pkg else nltk.data.find(f"tokenizers/{pkg}")
                except LookupError:
                    nltk.download(pkg, quiet=True)
        except Exception as exc_nltk:
            logger.warning("NLTK bootstrap issue: %s", exc_nltk)
        g2p = G2p()
        # Cache results per word to avoid recomputation across calls
        for w in words:
            if w in _phonemize_cache:
                ipa_per_word.append(_phonemize_cache[w])
                continue
            arpa = [t for t in g2p(w) if re.fullmatch(r"[A-Za-z]+\d?", t)]
            ipa = arpabet_tokens_to_ipa(arpa)
            _phonemize_cache[w] = ipa
            ipa_per_word.append(ipa)
        return ipa_per_word
    except Exception as exc:
        logger.warning("g2p_en fallback failed: %s", exc)
        return [[] for _ in words]


# Phoneme recognition from audio using wav2vec2
_phoneme_processor: Optional[object] = None
_phoneme_model: Optional[object] = None

# Allosaurus phoneme recognition model
_allosaurus_model: Optional[object] = None


def _lazy_allosaurus_model():
    """Lazy load Allosaurus phoneme recognition model."""
    global _allosaurus_model
    if _allosaurus_model is None:
        try:
            from allosaurus.app import read_recognizer
            logger.info("Loading Allosaurus phoneme recognition model")
            _allosaurus_model = read_recognizer()
            logger.info("Allosaurus model loaded successfully")
        except ImportError:
            raise ImportError("Allosaurus not installed. Install with: pip install allosaurus")
        except Exception as e:
            raise RuntimeError(f"Failed to load Allosaurus model: {e}")
    return _allosaurus_model


def _lazy_wav2vec2_phoneme():
    """Load wav2vec2 phoneme recognition model lazily."""
    global _phoneme_processor, _phoneme_model
    if _phoneme_processor is None or _phoneme_model is None:
        try:
            # Set up espeak-ng path if needed
            import os
            import glob
            if not os.environ.get("PHONEMIZER_ESPEAK_LIBRARY"):
                for p in (
                    "/opt/homebrew/Cellar/espeak-ng/*/lib/libespeak-ng.1.dylib",
                    "/opt/homebrew/lib/libespeak-ng.1.dylib",
                    "/opt/homebrew/lib/libespeak-ng.dylib",
                    "/usr/local/lib/libespeak-ng.dylib",
                ):
                    matches = glob.glob(p)
                    if matches:
                        os.environ["PHONEMIZER_ESPEAK_LIBRARY"] = matches[0]
                        logger.info(f"Found espeak-ng library at: {matches[0]}")
                        break
            
            from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
            _phoneme_processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-lv-60-espeak-cv-ft")
            _phoneme_model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-lv-60-espeak-cv-ft")
            _phoneme_model.eval()
            logger.info("Loaded wav2vec2 phoneme recognition model")
        except Exception as exc:
            logger.warning("Failed to load wav2vec2 phoneme model: %s", exc)
            raise
    return _phoneme_processor, _phoneme_model


def dedupe_phonemes(phonemes: List[str]) -> List[str]:
    """Remove consecutive duplicate phonemes to clean up wav2vec2 output."""
    if not phonemes:
        return []
    
    deduped = [phonemes[0]]
    for i in range(1, len(phonemes)):
        if phonemes[i] != phonemes[i-1]:
            deduped.append(phonemes[i])
    return deduped


def fix_allosaurus_oversegmentation(phonemes: List[str]) -> List[str]:
    """Fix Allosaurus over-segmentation and duplicate vowels to create proper English phonemes."""
    if not phonemes:
        return phonemes
    
    logger.debug(f"üîß Starting fix with {len(phonemes)} phonemes: {phonemes[:10]}...")
    
    # First pass: remove consecutive duplicates 
    deduplicated = []
    prev = None
    for phone in phonemes:
        if phone != prev:
            deduplicated.append(phone)
        prev = phone
    
    logger.debug(f"üîß After deduplication: {len(deduplicated)} phonemes: {deduplicated[:10]}...")
    
    # Second pass: reconstruct diphthongs
    fixed = []
    i = 0
    
    while i < len(deduplicated):
        current = deduplicated[i]
        next_phone = deduplicated[i + 1] if i + 1 < len(deduplicated) else None
        
        # Reconstruct common English diphthongs from Allosaurus segments
        if current == "a" and next_phone == "…™":
            fixed.append("a…™")  # price diphthong (my, I, time)
            logger.debug(f"üé≠ Combined a+…™ ‚Üí a…™ at position {i}")
            i += 2
        elif current == "e" and next_phone == "…™":
            fixed.append("e…™")  # face diphthong (name, day, play)
            logger.debug(f"üé≠ Combined e+…™ ‚Üí e…™ at position {i}")
            i += 2
        elif current == "a" and next_phone == " ä":
            fixed.append("a ä")  # mouth diphthong (now, house)
            logger.debug(f"üé≠ Combined a+ ä ‚Üí a ä at position {i}")
            i += 2
        elif current == "o" and next_phone == " ä":
            fixed.append("o ä")  # goat diphthong (go, show)
            logger.debug(f"üé≠ Combined o+ ä ‚Üí o ä at position {i}")
            i += 2
        elif current == "…î" and next_phone == "…™":
            fixed.append("…î…™")  # choice diphthong (boy, voice)
            logger.debug(f"üé≠ Combined …î+…™ ‚Üí …î…™ at position {i}")
            i += 2
        elif current == "…™" and next_phone == "…ô":
            fixed.append("…™…ô")  # near diphthong (here, near)
            logger.debug(f"üé≠ Combined …™+…ô ‚Üí …™…ô at position {i}")
            i += 2
        elif current == "…õ" and next_phone == "…ô":
            fixed.append("…õ…ô")  # square diphthong (there, care)
            logger.debug(f"üé≠ Combined …õ+…ô ‚Üí …õ…ô at position {i}")
            i += 2
        elif current == " ä" and next_phone == "…ô":
            fixed.append(" ä…ô")  # cure diphthong (sure, tour)
            logger.debug(f"üé≠ Combined  ä+…ô ‚Üí  ä…ô at position {i}")
            i += 2
        else:
            # Keep single phoneme
            fixed.append(current)
            i += 1
    
    logger.debug(f"üîß Final fixed phonemes: {len(fixed)} phonemes: {fixed[:10]}...")
    return fixed


def reconstruct_diphthongs(phonemes: List[str]) -> List[str]:
    """Reconstruct common English diphthongs that wav2vec2 might have separated."""
    if not phonemes:
        return phonemes
    
    reconstructed = []
    i = 0
    
    while i < len(phonemes):
        current = phonemes[i]
        next_phoneme = phonemes[i + 1] if i + 1 < len(phonemes) else None
        
        # Common English diphthongs to reconstruct
        if current == "a" and next_phoneme == "…™":
            reconstructed.append("a…™")  # like in "my", "I", "high"
            i += 2
        elif current == "e…™" or (current == "e" and next_phoneme == "…™"):
            reconstructed.append("e…™")  # like in "name", "day", "great"
            i += 2 if next_phoneme == "…™" else 1
        elif current == "a ä" or (current == "a" and next_phoneme == " ä"):
            reconstructed.append("a ä")  # like in "now", "house"
            i += 2 if next_phoneme == " ä" else 1
        elif current == "o ä" or (current == "o" and next_phoneme == " ä"):
            reconstructed.append("o ä")  # like in "go", "show"
            i += 2 if next_phoneme == " ä" else 1
        elif current == "…î…™" or (current == "…î" and next_phoneme == "…™"):
            reconstructed.append("…î…™")  # like in "boy", "voice"
            i += 2 if next_phoneme == "…™" else 1
        elif current == "…™…ô" or (current == "…™" and next_phoneme == "…ô"):
            reconstructed.append("…™…ô")  # like in "here", "near"
            i += 2 if next_phoneme == "…ô" else 1
        elif current == " ä…ô" or (current == " ä" and next_phoneme == "…ô"):
            reconstructed.append(" ä…ô")  # like in "sure", "tour"
            i += 2 if next_phoneme == "…ô" else 1
        elif current == "…õ…ô" or (current == "…õ" and next_phoneme == "…ô"):
            reconstructed.append("…õ…ô")  # like in "there", "care"
            i += 2 if next_phoneme == "…ô" else 1
        else:
            # Handle single vowels that might be missing
            if current in ["a", "e", "i", "o", "u"] and len(current) == 1:
                # Map single vowels to more likely IPA equivalents
                vowel_map = {
                    "a": "√¶",  # trap vowel
                    "e": "…õ",  # dress vowel  
                    "i": "…™",  # kit vowel
                    "o": "…í",  # lot vowel
                    "u": " ä"   # foot vowel
                }
                reconstructed.append(vowel_map.get(current, current))
            else:
                reconstructed.append(current)
            i += 1
    
    return reconstructed


def clean_phoneme_sequence(phonemes: List[str]) -> List[str]:
    """Advanced cleaning of phoneme sequences to fix wav2vec2 artifacts."""
    if not phonemes:
        return []
    
    cleaned = []
    i = 0
    while i < len(phonemes):
        current = phonemes[i]
        
        # Skip very short or invalid phonemes
        if len(current.strip()) == 0:
            i += 1
            continue
            
        # Look ahead to detect common artifacts
        if i < len(phonemes) - 1:
            next_phoneme = phonemes[i + 1]
            
            # Pattern: vowel + same vowel (e.g., "e …™ …™" ‚Üí "e …™")
            if current in ["e", "o", "a", "i", "u"] and next_phoneme == "…™" and current == "e":
                # Special case: "e …™" is actually the diphthong /e…™/
                cleaned.append("e…™")
                i += 2
                continue
            elif current in ["o"] and next_phoneme == " ä":
                # Special case: "o  ä" is actually the diphthong /o ä/
                cleaned.append("o ä") 
                i += 2
                continue
            elif current in ["a"] and next_phoneme == "…™":
                # Special case: "a …™" is actually the diphthong /a…™/
                cleaned.append("a…™")
                i += 2
                continue
            elif current in ["a"] and next_phoneme == " ä":
                # Special case: "a  ä" is actually the diphthong /a ä/
                cleaned.append("a ä")
                i += 2
                continue
        
        cleaned.append(current)
        i += 1
    
    # Final deduplication
    return dedupe_phonemes(cleaned)


def allosaurus_to_oxford_ipa(phone: str) -> str:
    """Convert Allosaurus IPA phonemes to Oxford English IPA system."""
    # Allosaurus uses standard IPA, but we need to map to Oxford English system
    mapping = {
        # Consonants - usually direct mapping
        "b": "b", "d": "d", "f": "f", "g": "g", "h": "h", "k": "k", "l": "l", 
        "m": "m", "n": "n", "p": "p", "r": "r", "s": "s", "t": "t", "v": "v", 
        "w": "w", "z": "z", "j": "j", "≈ã": "≈ã", "Œ∏": "Œ∏", "√∞": "√∞", " É": " É", 
        " í": " í", " ß": " ß", " §": " §", "t É": " ß", "d í": " §",
        
        # Vowels - map to Oxford English IPA
        "…ô": "…ô",      # schwa
        "…õ": "…õ",      # dress  
        "…™": "…™",      # kit
        "i": "iÀê",     # fleece (Allosaurus often uses 'i' for long vowel)
        "…ë": "…ë",      # palm/start
        "…î": "…î",      # thought
        " ä": " ä",      # foot
        "u": "uÀê",     # goose (Allosaurus often uses 'u' for long vowel)
        "√¶": "√¶",      # trap
        " å": " å",      # strut
        "…í": "…í",      # lot (UK)
        "…ú": "…úÀê",     # nurse
        "e": "e…™",     # Allosaurus 'e' often represents the face diphthong
        "o": "o ä",     # Allosaurus 'o' often represents the goat diphthong
        "a": "a…™",     # Allosaurus 'a' sometimes represents price diphthong
        
        # Common Allosaurus diphthongs  
        "a…™": "a…™",    # price
        "e…™": "e…™",    # face 
        "…î…™": "…î…™",    # choice
        "a ä": "a ä",    # mouth
        "o ä": "o ä",    # goat (US)
        "…ô ä": "…ô ä",    # goat (UK)
        "…™…ô": "…™…ô",    # near
        "…õ…ô": "…õ…ô",    # square
        " ä…ô": " ä…ô",    # cure
        
        # Long vowels from Allosaurus
        "iÀê": "iÀê",    # fleece
        "uÀê": "uÀê",    # goose
        "…ëÀê": "…ëÀê",    # palm
        "…îÀê": "…îÀê",    # thought
        "…úÀê": "…úÀê",    # nurse
        
        # R-colored vowels (common in Allosaurus US English)
        "…ö": "…ôr",     # unstressed syllabic r
        "…ù": "…úÀê",     # stressed r-colored vowel
        
        # Syllabic consonants
        "nÃ©": "n",      # syllabic n
        "mÃ©": "m",      # syllabic m
        "lÃ©": "l",      # syllabic l
        
        # Handle stress markers and diacritics
        "Àà": "",       # primary stress (remove)
        "Àå": "",       # secondary stress (remove)
        "Àê": "",       # length marker (handle separately)
    }
    
    # Clean the phoneme first
    clean_phone = phone.strip()
    
    # Handle length markers
    if clean_phone.endswith("Àê"):
        base = clean_phone[:-1]
        if base in ["i", "u", "…ë", "…î", "…ú"]:
            return base + "Àê"
        else:
            clean_phone = base
    
    # Apply mapping
    return mapping.get(clean_phone, clean_phone)


def improved_espeak_to_ipa(phone: str) -> str:
    """Convert espeak phonemes to Oxford English IPA with better mapping."""
    # Oxford English IPA mapping based on Language Confidence system
    mapping = {
        # Consonants (Oxford IPA standard)
        "tS": " ß", "dZ": " §", "N": "≈ã", "T": "Œ∏", "D": "√∞", 
        "S": " É", "Z": " í", "h": "h", "x": "h", "?": " î", "J": "j", "w": "w",
        "p": "p", "b": "b", "t": "t", "d": "d", "k": "k", "g": "g",
        "f": "f", "v": "v", "s": "s", "z": "z", "m": "m", "n": "n", "l": "l", "r": "r",
        
        # Vowels - Oxford English IPA system
        "@": "…ô",      # schwa (cup)
        "3": "…ú",      # nurse 
        "A": "…ë",      # father
        "I": "…™",      # sit
        "O": "…î",      # hawk
        "U": " ä",      # put
        "i": "i",      # cosy
        "u": "u",      # goose
        "e": "…õ",      # dress
        "o": "…í",      # hot (UK)
        "a": "√¶",      # trap (US) or "a" (UK)
        "V": " å",      # cup
        "Q": "…í",      # hot
        "E": "…õ",      # dress
        
        # Long vowels
        "A:": "…ëÀê",    # father (long)
        "3:": "…ôÀê",    # nurse (long) 
        "i:": "iÀê",    # fleece
        "O:": "…îÀê",    # hawk (long)
        "u:": "uÀê",    # goose (long)
        
        # Diphthongs (Oxford system) - multiple variations for wav2vec2
        "aI": "a…™",    # price (US) or " å…™" (UK)
        "AI": "a…™",    # alternative
        "aj": "a…™",    # alternative variant
        "eI": "e…™",    # face
        "EI": "e…™",    # alternative
        "ej": "e…™",    # alternative variant
        "OI": "…î…™",    # choice
        "oj": "…î…™",    # alternative
        "aU": "a ä",    # mouth
        "AU": "a ä",    # alternative
        "aw": "a ä",    # alternative variant
        "oU": "o ä",    # goat (US) or "…ô ä" (UK)
        "OU": "o ä",    # alternative
        "ow": "o ä",    # alternative variant
        "@U": "…ô ä",    # UK variant
        "I@": "…™…ô",    # here
        "e@": "…õÀê",    # square
        "u@": " ä…ô",    # cure
        
        # Additional vowel mappings wav2vec2 might produce
        "…ê": "√¶",      # near-open central vowel ‚Üí trap
        "…ö": "…ôr",     # r-colored schwa
        
        # Clean up common wav2vec2 artifacts
        "uu": "u", "ii": "i", "oo": "o", "aa": "a", "ee": "e",
        
        # Syllabic consonants
        "r=": "…ôr", "l=": "l", "n=": "n", "m=": "m",
    }
    
    # Apply mappings
    for espeak, ipa in mapping.items():
        phone = phone.replace(espeak, ipa)
    
    # Remove stress markers and other diacritics
    phone = phone.replace("'", "").replace(",", "").replace(":", "")
    
    return phone


def phonemes_from_audio(audio_16k: np.ndarray) -> List[str]:
    """Extract phonemes directly from 16kHz mono audio with intelligent reconstruction."""
    try:
        # Try Allosaurus first if available - MUCH better for phoneme recognition
        return phonemes_from_audio_allosaurus(audio_16k)
    except Exception as e:
        logger.warning(f"Allosaurus not available ({e}), using enhanced wav2vec2 with intelligent reconstruction")
        return phonemes_from_audio_wav2vec2(audio_16k)


def phonemes_from_audio_allosaurus(audio_16k: np.ndarray) -> List[str]:
    """Extract phonemes using Allosaurus - superior model for phoneme recognition."""
    try:
        import tempfile
        import soundfile as sf
        
        # Get cached Allosaurus model
        model = _lazy_allosaurus_model()
        
        # Enhanced audio preprocessing
        if len(audio_16k) == 0:
            return []
            
        # Normalize audio for Allosaurus (expects [-1, 1] range)
        audio_normalized = audio_16k / (np.max(np.abs(audio_16k)) + 1e-8)
        
        # Apply light noise reduction
        noise_threshold = 0.02
        audio_cleaned = np.where(np.abs(audio_normalized) < noise_threshold, 0, audio_normalized)
        
        # Scale to optimal range
        peak_amplitude = np.max(np.abs(audio_cleaned))
        if peak_amplitude > 0:
            audio_final = 0.9 * audio_cleaned / peak_amplitude
        else:
            audio_final = audio_cleaned
        
        # Allosaurus expects a wav file path, so create a temporary file
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
            sf.write(temp_wav.name, audio_final, 16000)
            temp_wav_path = temp_wav.name
        
        try:
            # Run Allosaurus phoneme recognition with English language
            phones_raw = model.recognize(temp_wav_path, lang_id="eng")
            logger.debug(f"Raw Allosaurus output: {phones_raw}")
            
            # Parse Allosaurus output - it's a simple space-separated phoneme sequence
            phones = []
            for phone in phones_raw.strip().split():
                phone = phone.strip()
                if phone and phone not in ["<unk>", "<sil>", "<spn>", ""]:
                    phones.append(phone)
            
            logger.debug(f"Extracted Allosaurus phones: {phones[:20]}...")
            
            # Convert Allosaurus IPA to Oxford English IPA
            ipa_phones = []
            for phone in phones:
                normalized = allosaurus_to_oxford_ipa(phone)
                if normalized and len(normalized.strip()) > 0:
                    ipa_phones.append(normalized)
            
            logger.debug(f"Oxford IPA phones: {ipa_phones[:20]}...")
            
            # Post-process to fix Allosaurus over-segmentation and create proper diphthongs
            logger.debug(f"üîß Before fix: {ipa_phones[:10]}...")
            processed_phones = fix_allosaurus_oversegmentation(ipa_phones)
            logger.debug(f"üîß After fix: {processed_phones[:10]}...")
            
            # Clean and normalize (preserve diphthongs that we just reconstructed)
            final_ipa = normalize_ipa_preserve_diphthongs(processed_phones)
            logger.info(f"ü¶é Allosaurus extraction: {len(phones)} raw ‚Üí {len(ipa_phones)} mapped ‚Üí {len(processed_phones)} processed ‚Üí {len(final_ipa)} final")
            
            # Debug: Check if fix actually worked
            has_consecutive_dups = any(processed_phones[i] == processed_phones[i+1] for i in range(len(processed_phones)-1))
            diphthongs_found = [p for p in processed_phones if len(p) > 1 and any(v in p for v in 'aeiou')]
            logger.info(f"üîß Fix results: consecutive_duplicates={has_consecutive_dups}, diphthongs={diphthongs_found[:5]}")
            
            return final_ipa
            
        finally:
            # Clean up temporary file
            import os
            try:
                os.unlink(temp_wav_path)
            except:
                pass
        
    except Exception as exc:
        logger.warning("Allosaurus phoneme recognition failed: %s", exc)
        raise exc


def phonemes_from_audio_wav2vec2(audio_16k: np.ndarray) -> List[str]:
    """Extract phonemes using wav2vec2 (fallback method)."""
    try:
        import torch
        processor, model = _lazy_wav2vec2_phoneme()
        
        # Enhanced audio preprocessing for better phoneme extraction
        if len(audio_16k) == 0:
            return []
            
        # 1. Normalize audio amplitude
        audio_normalized = audio_16k / (np.max(np.abs(audio_16k)) + 1e-8)
        
        # 2. Apply light noise reduction
        # Remove very quiet segments that might be noise
        noise_threshold = 0.02
        audio_cleaned = np.where(np.abs(audio_normalized) < noise_threshold, 0, audio_normalized)
        
        # 3. Ensure proper amplitude range for wav2vec2
        # The model expects values roughly in [-1, 1] range
        peak_amplitude = np.max(np.abs(audio_cleaned))
        if peak_amplitude > 0:
            # Scale to use 80% of the range to avoid clipping
            audio_normalized = 0.8 * audio_cleaned / peak_amplitude
        else:
            audio_normalized = audio_cleaned
        
        with torch.no_grad():
            inputs = processor(audio_normalized, sampling_rate=16000, return_tensors="pt", padding=True)
            logits = model(inputs.input_values).logits
            
            # Try multiple decoding strategies for better phoneme detection
            try:
                # Method 1: CTC beam search
                from torch.nn import functional as F
                log_probs = F.log_softmax(logits, dim=-1)
                
                # Use a confidence threshold to filter weak predictions
                confidence_threshold = 0.1
                probs = torch.exp(log_probs)
                max_probs, ids = torch.max(probs, dim=-1)
                
                # Mask out low-confidence predictions
                ids = ids.squeeze()
                confidences = max_probs.squeeze()
                
                # Only keep high-confidence phonemes
                confident_ids = ids[confidences > confidence_threshold]
                
                # Decode with better handling
                if len(confident_ids) > 0:
                    text = processor.batch_decode(confident_ids.unsqueeze(0))[0]
                else:
                    # Fallback to regular argmax if threshold too strict
                    ids = torch.argmax(log_probs, dim=-1)
                    text = processor.batch_decode(ids)[0]
                    
            except Exception as e:
                logger.debug(f"CTC beam search failed, using fallback: {e}")
                # Fallback to simple argmax
                ids = torch.argmax(logits, dim=-1)
                text = processor.batch_decode(ids)[0]
        
        logger.debug(f"Raw wav2vec2 output: {text}")
        
        # Extract individual phonemes, filter out word boundaries and empty tokens
        phones = [p for p in text.strip().split() if p and p != "|" and len(p.strip()) > 0]
        logger.debug(f"Extracted phones: {phones[:20]}...")
        
        # Convert espeak phonemes to Oxford IPA with improved mapping
        ipa_phones = []
        for phone in phones:
            normalized = improved_espeak_to_ipa(phone)
            if normalized and len(normalized.strip()) > 0 and normalized not in ["'", ",", ":"]:
                ipa_phones.append(normalized)
        
        logger.debug(f"IPA phones after mapping: {ipa_phones[:20]}...")
        
        # Post-process to reconstruct diphthongs that wav2vec2 might have separated
        ipa_phones = reconstruct_diphthongs(ipa_phones)
        
        logger.debug(f"IPA phones before cleaning: {ipa_phones[:20]}...")
        
        # Apply advanced cleaning to fix artifacts and create proper diphthongs
        ipa_phones = clean_phoneme_sequence(ipa_phones)
        
        # Additional cleaning for Oxford IPA consistency
        cleaned_phones = []
        for phone in ipa_phones:
            # Map to Oxford IPA standard phonemes
            if phone in ["b", " ß", "d", "√∞", "f", "g", "h", " §", "k", "l", "m", "n", "≈ã", "p", "r", "s", " É", "t", "Œ∏", "v", "w", "j", "z", " í"]:
                cleaned_phones.append(phone)  # Valid consonants
            elif phone in ["…õ", "…ô", "…™", "i", " ä", "…ë", "…î", "√¶", "u", "a", "…í", " å", "…ëÀê", "…õÀê", "…ôÀê", "iÀê", "…îÀê", "uÀê"]:
                cleaned_phones.append(phone)  # Valid vowels
            elif phone in ["a ä", "e…™", "…î…™", "a…™", "o ä", " å…™", "…ô ä", "…™…ô", " ä…ô"]:
                cleaned_phones.append(phone)  # Valid diphthongs
            else:
                # Try to map unknown phonemes to closest Oxford IPA equivalent
                if len(phone) == 1:
                    if phone in "aeiou":
                        # Map basic vowels to schwa as fallback
                        cleaned_phones.append("…ô")
                    elif phone.isalpha():
                        # Keep consonant-like sounds
                        cleaned_phones.append(phone)
        
        logger.debug(f"Final cleaned phones: {cleaned_phones[:20]}...")
        
        # Final IPA normalization using our existing function
        final_ipa = normalize_ipa(cleaned_phones)
        logger.debug(f"Final normalized IPA: {final_ipa[:20]}...")
        logger.info(f"üîç wav2vec2 extraction: {len(phones)} raw ‚Üí {len(ipa_phones)} mapped ‚Üí {len(final_ipa)} final")
        
        return final_ipa
        
    except Exception as exc:
        logger.warning("wav2vec2 phoneme recognition failed: %s", exc)
        return []



